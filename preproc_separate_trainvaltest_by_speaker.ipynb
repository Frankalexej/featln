{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from ssd_paths import *\n",
    "from paths import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_valid = pd.read_csv(os.path.join(sbsc_use_path, \"phone_random_validation.csv\"))\n",
    "random_test = pd.read_csv(os.path.join(sbsc_use_path, \"phone_random_test.csv\"))\n",
    "random_train = pd.read_csv(os.path.join(sbsc_use_path, \"phone_random_train.csv\"))\n",
    "\n",
    "guide_df = pd.read_csv(os.path.join(bsc_path, \"anno-log.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_speakers = random_valid[\"rec\"].str.slice(stop=3).unique().tolist()\n",
    "test_speakers = random_test[\"rec\"].str.slice(stop=3).unique().tolist()\n",
    "train_speakers = random_train[\"rec\"].str.slice(stop=3).unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output tensors for each set of speakers\n",
    "train_df = guide_df[guide_df[\"rec\"].str.slice(stop=3).isin(train_speakers)]\n",
    "val_df = guide_df[guide_df[\"rec\"].str.slice(stop=3).isin(valid_speakers)]\n",
    "test_df = guide_df[guide_df[\"rec\"].str.slice(stop=3).isin(test_speakers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"phone_anno_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(os.path.join(sbsc_use_path, prefix + \"train.csv\"), index=False)\n",
    "val_df.to_csv(os.path.join(sbsc_use_path, prefix + \"validation.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(sbsc_use_path, prefix + \"test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounded_namelist = [path.split(\".\")[0] for path in os.listdir(as_phones_extract_path) if path[0] == \"S\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(grounded_namelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_names, test_names = grounded_namelist[:len(grounded_namelist)//2], grounded_namelist[len(grounded_namelist)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['SSB0382',\n",
       "  'SSB0415',\n",
       "  'SSB0012',\n",
       "  'SSB0338',\n",
       "  'SSB0393',\n",
       "  'SSB0005',\n",
       "  'SSB0033',\n",
       "  'SSB0395',\n",
       "  'SSB0261'],\n",
       " ['SSB0057',\n",
       "  'SSB0043',\n",
       "  'SSB0011',\n",
       "  'SSB0394',\n",
       "  'SSB0016',\n",
       "  'SSB0299',\n",
       "  'SSB0375',\n",
       "  'SSB0273',\n",
       "  'SSB0139'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_names, test_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_bind(directory, namelist, target): \n",
    "    csv_files = sorted([f for f in namelist if f.startswith('S')])\n",
    "\n",
    "    # Read and concatenate the CSV files using pandas\n",
    "    dfs = []\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(os.path.join(directory, file))\n",
    "        dfs.append(df)\n",
    "\n",
    "    concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Save the concatenated dataframe as \"log.csv\"\n",
    "    concatenated_df.to_csv(target, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_csvs = []\n",
    "for i in os.listdir(as_phone_seg_anno_log_path):\n",
    "    if i.split(\".\")[0][:7] in val_names:\n",
    "        val_csvs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_bind(as_phone_seg_anno_log_path, val_csvs, os.path.join(ssd_aishell_path, \"phone_anno_validation.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csvs = []\n",
    "for i in os.listdir(as_phone_seg_anno_log_path):\n",
    "    if i.split(\".\")[0][:7] in test_names:\n",
    "        test_csvs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_bind(as_phone_seg_anno_log_path, test_csvs, os.path.join(ssd_aishell_path, \"phone_anno_test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with random set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlog = pd.read_csv(os.path.join(as_phone_seg_random_log_path, \"log.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = trainlog[\"rec\"].str[:7].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = set(speaker) - set(val_names) - set(test_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_csvs = []\n",
    "for i in os.listdir(as_phone_seg_random_log_path):\n",
    "    if i.split(\".\")[0][:7] in val_names:\n",
    "        val_csvs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csvs = []\n",
    "for i in os.listdir(as_phone_seg_random_log_path):\n",
    "    if i.split(\".\")[0][:7] in test_names:\n",
    "        test_csvs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csvs = []\n",
    "for i in os.listdir(as_phone_seg_random_log_path):\n",
    "    if i.split(\".\")[0][:7] in list(train_names):\n",
    "        train_csvs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_bind(as_phone_seg_random_log_path, train_csvs, os.path.join(ssd_aishell_path, \"phone_random_train.csv\"))\n",
    "csv_bind(as_phone_seg_random_log_path, val_csvs, os.path.join(ssd_aishell_path, \"phone_random_validation.csv\"))\n",
    "csv_bind(as_phone_seg_random_log_path, test_csvs, os.path.join(ssd_aishell_path, \"phone_random_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "featln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
