{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Run English\n",
    "Version 1.0  \n",
    "\n",
    "Version 2.0\n",
    "Added dropout layer. \n",
    "\n",
    "Version 3.0  \n",
    "Lowered dimensionality. \n",
    "\n",
    "Version 4.0  \n",
    "Changed ReLU to Tanh\n",
    "\n",
    "Version 5.0  \n",
    "Deleted resblock\n",
    "\n",
    "Version 6.0  \n",
    "Added back. Hiddim back to 3. \n",
    "\n",
    "Version 7.0  \n",
    "This time using MF data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchinfo import summary\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure\n",
    "import pickle\n",
    "\n",
    "from paths import *\n",
    "# from model_config import *\n",
    "from model_dataset import UngroundedSoundDataset, GroundedSoundDataset\n",
    "# from model_model import *\n",
    "from my_utils import get_timestamp\n",
    "from misc_recorder import *\n",
    "from misc_progress_bar import draw_progress_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localize Dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_ = model_eng_save_dir\n",
    "\n",
    "random_train_data_ = os.path.join(bsc_use_path, \"phone_random_train.mfcc\")\n",
    "radnom_valid_data_ = os.path.join(bsc_use_path, \"phone_random_validation.mfcc\")\n",
    "anno_test_data_ = os.path.join(bsc_use_path, \"phone_anno_test.mfcc\")\n",
    "\n",
    "random_train_guide_ = os.path.join(bsc_use_path, \"phone_random_train.csv\")\n",
    "random_valid_guide_ = os.path.join(bsc_use_path, \"phone_random_validation.csv\")\n",
    "anno_test_guide_ = os.path.join(bsc_use_path, \"phone_anno_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "READ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "LOADER_WORKER = 16\n",
    "\n",
    "FRAMES_IN_SEGMENT = 25\n",
    "\n",
    "MFCC_DIM = 13\n",
    "INPUT_DIM = FRAMES_IN_SEGMENT * MFCC_DIM * 3\n",
    "OUTPUT_DIM = FRAMES_IN_SEGMENT * MFCC_DIM\n",
    "# let's still maintain these interdims but just ignore them when building the model \n",
    "INTER_DIM_1 = 256\n",
    "INTER_DIM_2 = 64\n",
    "INTER_DIM_3 = 16\n",
    "LATENT_DIM = 3\n",
    "\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Training Stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF-1119195807\n"
     ]
    }
   ],
   "source": [
    "if READ: \n",
    "    ts = \"1116223120\"\n",
    "else: \n",
    "    ts = str(get_timestamp())\n",
    "\n",
    "train_name = \"MF\"\n",
    "model_save_dir = os.path.join(model_save_, f\"{train_name}-{ts}\")\n",
    "mk(model_save_dir)\n",
    "\n",
    "stop_epoch = \"32\"\n",
    "trainhist_name = \"train.hst\"\n",
    "valhist_name = \"val.hst\"\n",
    "valacc_name = \"valacc.hst\"\n",
    "print(f\"{train_name}-{ts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Loss Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = ListRecorder(os.path.join(model_save_dir, trainhist_name))\n",
    "valid_losses = ListRecorder(os.path.join(model_save_dir, valhist_name))\n",
    "\n",
    "valid_accs = ListRecorder(os.path.join(model_save_dir, valacc_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE = \"full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1109614 1109614\n",
      "163388 163388\n"
     ]
    }
   ],
   "source": [
    "train_ds = UngroundedSoundDataset(random_train_data_, random_train_guide_)\n",
    "valid_ds = UngroundedSoundDataset(radnom_valid_data_, random_valid_guide_)\n",
    "\n",
    "if TYPE == \"part\": \n",
    "    use_len = int(0.3 * len(train_ds))\n",
    "    remain_len = len(train_ds) - use_len\n",
    "    use_train_ds, remain_ds = random_split(train_ds, [use_len, remain_len])\n",
    "\n",
    "    use_len = int(0.3 * len(valid_ds))\n",
    "    remain_len = len(valid_ds) - use_len\n",
    "    use_valid_ds, remain_ds = random_split(valid_ds, [use_len, remain_len])\n",
    "\n",
    "    train_loader = DataLoader(use_train_ds, batch_size=BATCH_SIZE, \n",
    "                            shuffle=True, \n",
    "                            num_workers=LOADER_WORKER)\n",
    "    train_num = len(train_loader.dataset)\n",
    "\n",
    "    valid_loader = DataLoader(use_valid_ds, batch_size=BATCH_SIZE, \n",
    "                            shuffle=False, \n",
    "                            num_workers=LOADER_WORKER)\n",
    "elif TYPE == \"full\": \n",
    "    use_train_ds = train_ds\n",
    "    use_valid_ds = valid_ds\n",
    "    \n",
    "elif TYPE == \"same\":\n",
    "    train_len = int(0.8 * len(train_ds))\n",
    "    valid_len = len(train_ds) - train_len\n",
    "    use_train_ds, use_valid_ds = random_split(train_ds, [train_len, valid_len])\n",
    "\n",
    "train_loader = DataLoader(use_train_ds, batch_size=BATCH_SIZE, \n",
    "                        shuffle=True, \n",
    "                        num_workers=LOADER_WORKER)\n",
    "train_num = len(train_loader.dataset)\n",
    "\n",
    "valid_loader = DataLoader(use_valid_ds, batch_size=BATCH_SIZE, \n",
    "                        shuffle=False, \n",
    "                        num_workers=LOADER_WORKER)\n",
    "valid_num = len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1109614, 163388)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num, valid_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from model_config import *\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.lin1 = nn.Linear(n_chans, n_chans)\n",
    "        self.lin2 = nn.Linear(n_chans, n_chans)\n",
    "        self.batch_norm = nn.BatchNorm1d(num_features=n_chans)  # <5>\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.lin1(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.lin2(out)\n",
    "        out = self.batch_norm(out)\n",
    "        out = self.relu(out)\n",
    "        out = out + x\n",
    "        return out\n",
    "\n",
    "class LinPack(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super(LinPack, self).__init__()\n",
    "        self.lin = nn.Linear(n_in, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batch_norm = nn.BatchNorm1d(num_features=n_out)\n",
    "        # self.dropout = nn.Dropout(p=DROPOUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.batch_norm(x)\n",
    "        # x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResAE(nn.Module):\n",
    "    def __init__(self, input_dim=INPUT_DIM, inter_dim1=INTER_DIM_1, inter_dim2=INTER_DIM_2, inter_dim3=INTER_DIM_3, latent_dim=LATENT_DIM, output_dim=OUTPUT_DIM):\n",
    "        super(ResAE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            LinPack(input_dim, inter_dim1), \n",
    "            ResBlock(inter_dim1), \n",
    "            # ResBlock(inter_dim1), \n",
    "            nn.Linear(inter_dim1, latent_dim), \n",
    "            # nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.decoder =  nn.Sequential(\n",
    "            LinPack(latent_dim, inter_dim1), \n",
    "            ResBlock(inter_dim1), \n",
    "            # ResBlock(inter_dim1), \n",
    "            nn.Linear(inter_dim1, output_dim),\n",
    "            # nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        # initialize the weights\n",
    "        # self.encoder.apply(self.init_weights)\n",
    "        # self.encoder.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            m.bias.data.fill_(0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        org_size = x.size()\n",
    "        y_size = (org_size[0], org_size[1], org_size[2] // 3)\n",
    "        batch = org_size[0]\n",
    "        x = x.view(batch, -1)\n",
    "\n",
    "        h = self.encoder(x)\n",
    "        recon_x = self.decoder(h).view(size=y_size)\n",
    "\n",
    "        return recon_x\n",
    "    \n",
    "    def encode(self, x):\n",
    "        org_size = x.size()\n",
    "        y_size = (org_size[0], org_size[1], org_size[2] // 3)\n",
    "        batch = org_size[0]\n",
    "        x = x.view(batch, -1)\n",
    "\n",
    "        h = self.encoder(x)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): LinPack(\n",
       "      (lin): Linear(in_features=975, out_features=256, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (batch_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (lin1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (lin2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (batch_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): LinPack(\n",
       "      (lin): Linear(in_features=3, out_features=256, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (batch_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (lin1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (lin2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (batch_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Linear(in_features=256, out_features=325, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_loss = nn.MSELoss(reduction='mean')\n",
    "# recon_loss = nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ResAE(INPUT_DIM, INTER_DIM_1, INTER_DIM_2, INTER_DIM_3, LATENT_DIM, OUTPUT_DIM)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Define the file path and name\n",
    "model_info_file = os.path.join(model_save_dir, 'model.txt')\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(model_info_file, 'w') as f:\n",
    "    f.write(str(model))\n",
    "    f.write('\\n\\n')\n",
    "    f.write(str(summary(model, input_size=(BATCH_SIZE, FRAMES_IN_SEGMENT, MFCC_DIM * 3))))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600392"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model if READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if READ: \n",
    "    valid_losses.read()\n",
    "    train_losses.read()\n",
    "\n",
    "    model_raw_name = f\"{stop_epoch}\"\n",
    "    model_name = model_raw_name + \".pt\"\n",
    "    model_path = os.path.join(model_save_dir, model_name)\n",
    "    state = torch.load(model_path)\n",
    "\n",
    "    model.load_state_dict(state)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BASE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(): \n",
    "    best_valid_loss = 1000000\n",
    "    best_valid_loss_epoch = 0\n",
    "    for epoch in range(BASE, BASE + EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        train_num = len(train_loader)    # train_loader\n",
    "        for idx, (x, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            x_hat = model(x)\n",
    "            loss = recon_loss(x_hat, y)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            return x_hat\n",
    "            \n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            # 这个函数计算的是全局梯度范数\n",
    "            # torch.nn.utils.clip_grad_norm(parameters=model.parameters(), max_norm=5, norm_type=2)\n",
    "            # torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=5, norm_type=2)\n",
    "            # parameters: an iterable of Variables that will have gradients normalized\n",
    "            # max_norm: max norm of the gradients(阈值设定)\n",
    "            # norm_type: type of the used p-norm. Can be'inf'for infinity norm(定义范数类型)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # draw_progress_bar(idx, train_num)\n",
    "\n",
    "        train_losses.append(train_loss / train_num)\n",
    "\n",
    "        last_model_name = f\"{epoch}.pt\"\n",
    "        torch.save(model.state_dict(), os.path.join(model_save_dir, last_model_name))\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.\n",
    "        valid_num = len(valid_loader)\n",
    "        for idx, (x, y) in enumerate(valid_loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            x_hat = model(x)\n",
    "            loss = recon_loss(x_hat, y)\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            # draw_progress_bar(idx, valid_num)\n",
    "\n",
    "        avg_valid_loss = valid_loss / valid_num\n",
    "        valid_losses.append(avg_valid_loss)\n",
    "        if avg_valid_loss < best_valid_loss: \n",
    "            best_valid_loss = avg_valid_loss\n",
    "            best_valid_loss_epoch = epoch\n",
    "\n",
    "        draw_learning_curve(losses=(train_losses.get(), valid_losses.get()), \n",
    "                            others=best_valid_loss_epoch, \n",
    "                            epoch=str(epoch))\n",
    "        train_losses.save()\n",
    "        valid_losses.save()\n",
    "\n",
    "    return best_valid_loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1261.5897206106126,\n",
       "  1145.2250076489465,\n",
       "  1056.8426152981415,\n",
       "  1003.1926453782476,\n",
       "  988.7651548785459,\n",
       "  977.5234523417215,\n",
       "  958.884836201918,\n",
       "  930.3075535781655,\n",
       "  930.0974991116557,\n",
       "  839.7000297294768,\n",
       "  801.2702316754692,\n",
       "  751.8868951908858,\n",
       "  721.7273183403818,\n",
       "  701.1033072370697,\n",
       "  685.0805036606673,\n",
       "  670.9462205031614,\n",
       "  652.6661156445914,\n",
       "  631.8468206526636,\n",
       "  624.1020487303552,\n",
       "  614.9340986736368,\n",
       "  597.4337110933272,\n",
       "  585.6371562033513],\n",
       " [8066.214199279209,\n",
       "  50240.618178125835,\n",
       "  49392.71047249124,\n",
       "  1236.7067958207945,\n",
       "  2603.355775786864,\n",
       "  320352369.37303525,\n",
       "  827415.1738053025,\n",
       "  337387575.43093526,\n",
       "  5393561.757507086,\n",
       "  118581683.67628023,\n",
       "  522472.0461080011,\n",
       "  601490.8355293572,\n",
       "  9935239.99042388,\n",
       "  3753695732.0480533,\n",
       "  12748166.083453303,\n",
       "  7965481561.895514,\n",
       "  146708710.33326343,\n",
       "  21101902569.013344,\n",
       "  24351296562.329025,\n",
       "  66544410876.90544,\n",
       "  7037396031.801556,\n",
       "  188844556672.22488])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses.get(), valid_losses.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    best_valid_loss_epoch = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsds = GroundedSoundDataset(anno_data_, anno_guide_test_)\n",
    "eval_loader = DataLoader(gsds, batch_size=BATCH_SIZE, shuffle=False, num_workers=LOADER_WORKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): LinPack(\n",
       "      (lin): Linear(in_features=975, out_features=64, bias=True)\n",
       "      (relu): Tanh()\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (lin1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (lin2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (relu): Tanh()\n",
       "    )\n",
       "    (2): Linear(in_features=64, out_features=3, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): LinPack(\n",
       "      (lin): Linear(in_features=3, out_features=64, bias=True)\n",
       "      (relu): Tanh()\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (lin1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (lin2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (relu): Tanh()\n",
       "    )\n",
       "    (2): Linear(in_features=64, out_features=325, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_epoch = \"59\"\n",
    "model_raw_name = f\"{stop_epoch}\"\n",
    "model_name = model_raw_name + \".pt\"\n",
    "model_path = os.path.join(model_save_dir, model_name)\n",
    "state = torch.load(model_path)\n",
    "\n",
    "model.load_state_dict(state)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ldlmdl/anaconda3/envs/featln/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "hiddens = None\n",
    "tags = None\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, (s, e, t) in enumerate(eval_loader):\n",
    "        s = s.to(device)\n",
    "        hidden = model.encode(s)\n",
    "        hidden = hidden.cpu().data.numpy()\n",
    "\n",
    "        if hiddens is not None: \n",
    "            hiddens = np.concatenate((hiddens, hidden), axis=0)\n",
    "            tags = np.concatenate((tags, t), axis=0)\n",
    "        else: \n",
    "            hiddens = hidden\n",
    "            tags = t\n",
    "num_phones = np.unique(tags).shape[0]\n",
    "kmeansmodel = KMeans(n_clusters=num_phones) # , random_state=0\n",
    "clusters = kmeansmodel.fit_predict(hiddens)\n",
    "np.save(model_save_dir + \"_hc.npy\", clusters)\n",
    "np.save(model_save_dir + \"_hr.npy\", hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, c, v = homogeneity_completeness_v_measure(tags, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.005978210035328847, 0.005086944667294446, 0.005496682961327691)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h, c, v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "featln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
