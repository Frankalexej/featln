{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy import signal\n",
    "import time\n",
    "\n",
    "from paths import *\n",
    "from misc_progress_bar import draw_progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCCTransform(nn.Module): \n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, waveform, sr=16000): \n",
    "        # extract mfcc\n",
    "        feature = torchaudio.compliance.kaldi.mfcc(waveform, sample_frequency=sr)\n",
    "\n",
    "        # add deltas\n",
    "        d1 = torchaudio.functional.compute_deltas(feature)\n",
    "        d2 = torchaudio.functional.compute_deltas(d1)\n",
    "        feature = torch.cat([feature, d1, d2], dim=-1)\n",
    "\n",
    "        # Apply normalization (CMVN)\n",
    "        eps = 1e-9\n",
    "        mean = feature.mean(0, keepdim=True)\n",
    "        std = feature.std(0, keepdim=True, unbiased=False)\n",
    "        feature = (feature - mean) / (std + eps)\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = MFCCTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_feats = torch.empty((0, 25, 39))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  ] 0%\t"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ldlmdl/Documents/featln/scripts/try.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ldlmdl/Documents/featln/scripts/try.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     resampled_wave \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(signal\u001b[39m.\u001b[39mresample(wave, \u001b[39m4240\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ldlmdl/Documents/featln/scripts/try.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     single_mfccfeats \u001b[39m=\u001b[39m transformer(resampled_wave)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ldlmdl/Documents/featln/scripts/try.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     mfcc_feats \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((mfcc_feats, single_mfccfeats\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ldlmdl/Documents/featln/scripts/try.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mexcept\u001b[39;00m: \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ldlmdl/Documents/featln/scripts/try.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "src_ = \"/home/ldlmdl/Documents/wavln/src/bsc/phone_seg_random/\"\n",
    "total = len(os.listdir(src_))\n",
    "for idx, file in enumerate(os.listdir(src_)):\n",
    "    draw_progress_bar(idx, total)\n",
    "    try: \n",
    "        wave, sr = torchaudio.load(os.path.join(src_, file))\n",
    "        resampled_wave = torch.tensor(signal.resample(wave, 4240, axis=1))\n",
    "        single_mfccfeats = transformer(resampled_wave)\n",
    "        mfcc_feats = torch.cat((mfcc_feats, single_mfccfeats.unsqueeze(0)), dim=0)\n",
    "    except: \n",
    "        print(\"!\")\n",
    "\n",
    "torch.save(mfcc_feats, os.path.join(bsc_path, \"random.mfcc\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1438841"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "featln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
