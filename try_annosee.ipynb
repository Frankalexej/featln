{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from ssd_paths import *\n",
    "from sound_proc import *\n",
    "from mio import *\n",
    "from misc_tools import *\n",
    "from misc_progress_bar import draw_progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide = pd.read_csv(as_phones_extract_path + 'SSB0016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide[\"rec\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regenerate anno set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['phone_anno_test.csv',\n",
       " 'phone_anno_test.mfcc',\n",
       " 'phone_anno_validation.csv',\n",
       " 'phone_anno_validation.mfcc',\n",
       " 'phone_random_test.csv',\n",
       " 'phone_random_test.mfcc',\n",
       " 'phone_random_train.csv',\n",
       " 'phone_random_train.mfcc',\n",
       " 'phone_random_validation.csv',\n",
       " 'phone_random_validation.mfcc']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(as_use_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide = pd.read_csv(as_use_path + 'phone_anno_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SSB0016', 'SSB0043', 'SSB0139', 'SSB0273', 'SSB0375', 'SSB0394']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide[\"rec\"].str.slice(stop=7).unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annospeakers = ['SSB0033', 'SSB0261', 'SSB0382', 'SSB0393', 'SSB0395', 'SSB0415']\n",
    "annospeakers = ['SSB0016', 'SSB0043', 'SSB0139', 'SSB0273', 'SSB0375', 'SSB0394']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_and_cut(wave_path, wave_name, filtered_df, params, no_real_cut=False):\n",
    "    # filtered_df = filter_tokens_and_get_df(annos_path, keepSIL=False)\n",
    "    filtered_df = filtered_df[filtered_df[\"rec\"] == wave_name]\n",
    "    flat_starts, flat_ends, c_duration = filtered_df[\"start_time\"].to_numpy(), filtered_df[\"end_time\"].to_numpy(), filtered_df[\"duration\"].to_numpy()\n",
    "\n",
    "    if not no_real_cut: \n",
    "        sp = Sound_Proc()\n",
    "    \n",
    "        rec, sample_rate = torchaudio.load(wave_path)\n",
    "\n",
    "        cut_recs = sp.cut_rec(rec, flat_starts, flat_ends)\n",
    "\n",
    "        # NOTE: This is added because a very small proportion of the data are strangely having zero n_frames (which I don't know yet why)\n",
    "        # to filter them out, I added this n_frames\n",
    "        cut_n_frames = [cut_rec.shape[1] for cut_rec in cut_recs]\n",
    "        cut_n_frames = np.array(cut_n_frames)\n",
    "    else: \n",
    "        pass\n",
    "        # ref_anno_df = pd.read_csv(os.path.join(word_seg_anno_log_ref_path, os.path.basename(annos_path)))\n",
    "        # assert ref_anno_df.shape[0] == filtered_df.shape[0]\n",
    "        # cut_n_frames = ref_anno_df[\"n_frames\"].to_numpy()\n",
    "        # cut_recs = []\n",
    "    \n",
    "    tokens = filtered_df[\"token\"].to_numpy()\n",
    "    \n",
    "    cst, cet = flat_starts, flat_ends\n",
    "    \n",
    "    \n",
    "    # Framify\n",
    "    # Create a dictionary with the three lists as values and the column names as keys\n",
    "    data = {'rec': wave_name, \"idx\": list(map(\"{:08d}\".format, range(len(c_duration)))), 'start_time': cst, 'end_time': cet, 'token': tokens, 'duration': c_duration, 'n_frames':cut_n_frames}\n",
    "    # Create a Pandas DataFrame from the dictionary\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return cut_recs, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filter_tokens_and_get_df(os.path.join(as_phones_extract_path, \"log.csv\"), keepSIL=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_work_pool = []\n",
    "for speaker in annospeakers:\n",
    "    my_work_pool.extend(glob.glob(f\"{speaker}*.wav\", root_dir=as_wav_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 99%\t"
     ]
    }
   ],
   "source": [
    "total = len(my_work_pool)\n",
    "\n",
    "for idx, rec_name in enumerate(my_work_pool): \n",
    "    rec_raw, ext = os.path.splitext(rec_name)\n",
    "    draw_progress_bar(idx, total)\n",
    "    cut_recs, corr_df = open_and_cut(\n",
    "        os.path.join(as_wav_path, rec_name), \n",
    "        rec_raw, filtered_df, \n",
    "        None, \n",
    "        no_real_cut=False\n",
    "    )\n",
    "    save_cut_waves_and_log(\n",
    "        save_dir=as_phone_seg_anno_new_path, \n",
    "        log_dir=as_phone_seg_anno_new_log_path, \n",
    "        cut_list=cut_recs, \n",
    "        corr_df=corr_df, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_bind(log_dir): \n",
    "    # List all the CSV files in the directory that start with 's'\n",
    "    directory = log_dir\n",
    "    csv_files = sorted([f for f in os.listdir(directory) if f.startswith('S') and f.endswith('.csv')])\n",
    "\n",
    "    # Read and concatenate the CSV files using pandas\n",
    "    dfs = []\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(os.path.join(directory, file))\n",
    "        dfs.append(df)\n",
    "\n",
    "    concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Save the concatenated dataframe as \"log.csv\"\n",
    "    concatenated_df.to_csv(os.path.join(directory, 'log.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_bind(as_phone_seg_anno_new_log_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "featln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
